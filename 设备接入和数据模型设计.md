# 设备接入和监控数据模型设计

## 概述

针对3000+设备（路由器、交换机AC、AP）的接入需求，设计完整的设备接入协议、数据传输格式和数据存储模型。

## 设备接入架构

### 1. 设备接入协议设计

#### 支持的接入方式

| 设备类型 | 接入方式 | 协议 | 端口 | 数据格式 |
|----------|----------|------|------|----------|
| 路由器 | SNMP v2c/v3 | UDP | 161 | SNMP OID |
| 交换机AC | SNMP v2c/v3 + WebSocket | UDP/TCP | 161/8080 | SNMP + JSON |
| AP | SNMP v2c/v3 + CoAP | UDP | 161/5683 | SNMP + CBOR |

#### WebSocket 设备接入服务

```java
@Component
@Slf4j
public class DeviceWebSocketServer {
    
    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(4);
    private final Map<String, DeviceConnection> deviceConnections = new ConcurrentHashMap<>();
    
    @OnOpen
    public void onOpen(Session session, @PathParam("deviceId") String deviceId) {
        log.info("Device connected: {} - {}", deviceId, session.getId());
        
        DeviceConnection connection = new DeviceConnection(session, deviceId);
        deviceConnections.put(deviceId, connection);
        
        // 启动心跳检测
        scheduleHeartbeat(deviceId);
        
        // 发送设备配置
        sendDeviceConfig(deviceId);
    }
    
    @OnMessage
    public void onMessage(String message, Session session) {
        try {
            DeviceDataMessage dataMessage = JSON.parseObject(message, DeviceDataMessage.class);
            processDeviceData(dataMessage);
        } catch (Exception e) {
            log.error("Failed to process device message: {}", message, e);
            sendErrorResponse(session, "INVALID_MESSAGE_FORMAT");
        }
    }
    
    @OnClose
    public void onClose(Session session, @PathParam("deviceId") String deviceId) {
        log.info("Device disconnected: {} - {}", deviceId, session.getId());
        
        DeviceConnection connection = deviceConnections.remove(deviceId);
        if (connection != null) {
            connection.close();
            
            // 更新设备状态为离线
            updateDeviceStatus(deviceId, DeviceStatus.OFFLINE);
            
            // 触发离线告警
            triggerDeviceOfflineAlert(deviceId);
        }
    }
    
    private void processDeviceData(DeviceDataMessage message) {
        // 数据验证
        if (!validateDeviceData(message)) {
            log.warn("Invalid device data from device: {}", message.getDeviceId());
            return;
        }
        
        // 发送到Kafka消息队列
        kafkaTemplate.send("device-data-raw", message.getDeviceId(), 
                          JSON.toJSONString(message));
        
        // 更新设备在线状态
        updateDeviceStatus(message.getDeviceId(), DeviceStatus.ONLINE);
        
        // 缓存最新数据
        cacheLatestDeviceData(message);
    }
}
```

### 2. SNMP 监控服务

```java
@Service
@Slf4j
public class SNMPMonitoringService {
    
    private final Snmp snmp;
    private final Map<String, DeviceOIDConfig> deviceOidConfigs;
    
    // 标准设备OID定义
    private static final Map<String, String> STANDARD_OIDS = Map.of(
        "cpu_usage", "1.3.6.1.4.1.2021.11.9.0",        // system.cpu.user
        "memory_usage", "1.3.6.1.4.1.2021.4.5.0",      // realTotalReal
        "disk_usage", "1.3.6.1.4.1.2021.9.1.8.1",      // hrStorageUsed.1
        "network_in", "1.3.6.1.2.1.2.2.1.10",          // ifInOctets
        "network_out", "1.3.6.1.2.1.2.2.1.16",         // ifOutOctets
        "device_name", "1.3.6.1.2.1.1.5.0",            // sysName
        "uptime", "1.3.6.1.2.1.1.3.0"                  // sysUpTime
    );
    
    @Scheduled(fixedRate = 30000) // 30秒轮询一次
    public void pollAllDevices() {
        List<Device> activeDevices = deviceService.getActiveDevices();
        
        activeDevices.parallelStream().forEach(device -> {
            try {
                DeviceMetrics metrics = pollDeviceMetrics(device);
                if (metrics != null) {
                    // 发送到数据处理管道
                    kafkaTemplate.send("device-metrics", device.getId(), 
                                      JSON.toJSONString(metrics));
                }
            } catch (Exception e) {
                log.error("Failed to poll device metrics: {}", device.getId(), e);
                handleDevicePollingError(device, e);
            }
        });
    }
    
    private DeviceMetrics pollDeviceMetrics(Device device) throws IOException {
        String address = device.getIpAddress() + "/" + device.getSnmpPort();
        
        try (UdpTarget target = new UdpTarget(address)) {
            target.setRetries(2);
            target.setTimeout(5000);
            
            // 构建SNMP请求
            List<OID> oids = buildOIDList(device.getType());
            PDU request = new PDU();
            request.setType(PDU.GET);
            oids.forEach(request::add);
            
            ResponseEvent response = target.get(request, getReadCommunity(device));
            
            if (response.getResponse() != null && 
                response.getResponse().getErrorStatus() == PDU.noError) {
                
                return parseSNMPResponse(response.getResponse(), device);
            }
        }
        
        return null;
    }
    
    private List<OID> buildOIDList(DeviceType deviceType) {
        List<String> oidList = new ArrayList<>(STANDARD_OIDS.values());
        
        // 根据设备类型添加特定OID
        switch (deviceType) {
            case ROUTER:
                oidList.addAll(Arrays.asList(
                    "1.3.6.1.4.1.9.2.1.58.0",  // Cisco CPU
                    "1.3.6.1.4.1.9.2.1.8.0"   // Cisco Memory
                ));
                break;
            case SWITCH:
                oidList.addAll(Arrays.asList(
                    "1.3.6.1.4.1.9.5.1.4.1.1.5", // Cisco VLAN info
                    "1.3.6.1.2.1.17.4.3.0"      // Bridge port learning
                ));
                break;
            case ACCESS_POINT:
                oidList.addAll(Arrays.asList(
                    "1.3.6.1.4.1.14176.1.1.1.1.0", // AP Model
                    "1.3.6.1.4.1.14176.1.1.1.3.0"  // AP Serial Number
                ));
                break;
        }
        
        return oidList.stream().map(OID::new).collect(Collectors.toList());
    }
}
```

## 数据传输协议

### 1. 设备上报数据格式

```json
{
  "deviceId": "RTR-001",
  "timestamp": "2025-01-16T10:30:00.000Z",
  "deviceType": "ROUTER",
  "dataVersion": "2.1",
  "metrics": {
    "cpu": {
      "usage": 45.6,
      "load_1min": 1.2,
      "load_5min": 0.8,
      "load_15min": 0.6
    },
    "memory": {
      "total": 8589934592,
      "used": 4294967296,
      "usage": 50.0,
      "available": 4294967296
    },
    "disk": [
      {
        "device": "/dev/sda1",
        "total": 107374182400,
        "used": 53687091200,
        "usage": 50.0,
        "mount_point": "/"
      }
    ],
    "network": {
      "interfaces": [
        {
          "name": "eth0",
          "rx_bytes": 1024000,
          "tx_bytes": 512000,
          "rx_packets": 1000,
          "tx_packets": 800,
          "rx_errors": 0,
          "tx_errors": 0
        }
      ]
    },
    "temperature": {
      "cpu": 65.0,
      "system": 42.0
    },
    "power": {
      "voltage": 12.0,
      "current": 2.5,
      "power": 30.0
    }
  },
  "alerts": [
    {
      "type": "HIGH_CPU_USAGE",
      "severity": "WARNING",
      "message": "CPU使用率超过70%",
      "value": 45.6,
      "threshold": 70.0
    }
  ],
  "location": {
    "building": "A栋",
    "floor": "3楼",
    "room": "网络机房",
    "rack": "R01",
    "position": "U15"
  }
}
```

### 2. 命令下发格式

```json
{
  "commandId": "CMD-202501161030001",
  "deviceId": "RTR-001",
  "timestamp": "2025-01-16T10:30:00.000Z",
  "commandType": "CONFIG_UPDATE",
  "priority": "HIGH",
  "timeout": 300,
  "payload": {
    "action": "UPDATE_ROUTING_TABLE",
    "parameters": {
      "routes": [
        {
          "destination": "192.168.1.0/24",
          "next_hop": "192.168.0.1",
          "metric": 10
        }
      ]
    }
  },
  "expectedResponse": true
}
```

## 数据模型设计

### 1. 时序数据库模型 (InfluxDB)

#### Measurement 设计

**设备基础指标表 (device_metrics)**
```sql
-- 字段设计
device_id: string (tag)
device_type: string (tag)
location: string (tag)
timestamp: time

-- 数值字段
cpu_usage: float
memory_usage: float
disk_usage: float
network_in: integer
network_out: integer
temperature_cpu: float
temperature_system: float
voltage: float
current: float
power: float
uptime: integer

-- 索引查询示例
-- 查询特定设备最近1小时的指标
SELECT mean(cpu_usage), mean(memory_usage) 
FROM device_metrics 
WHERE device_id = 'RTR-001' 
  AND time > now() - 1h 
GROUP BY time(1m);

-- 查询某个位置所有设备的当前状态
SELECT * FROM device_metrics 
WHERE location = 'A栋3楼网络机房' 
  AND time > now() - 5m 
ORDER BY time DESC;
```

**设备告警表 (device_alerts)**
```sql
-- 告警记录
device_id: string (tag)
device_type: string (tag)
alert_type: string (tag)
severity: string (tag)
location: string (tag)
timestamp: time

-- 告警内容
alert_message: string
value: float
threshold: float
duration: integer  -- 告警持续时间(秒)
status: string     -- open, acknowledged, resolved
```

### 2. 关系数据库模型 (PostgreSQL)

#### 设备管理表

```sql
-- 设备基础信息表
CREATE TABLE devices (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    device_code VARCHAR(50) UNIQUE NOT NULL,
    name VARCHAR(255) NOT NULL,
    type VARCHAR(20) NOT NULL CHECK (type IN ('ROUTER', 'SWITCH', 'AP', 'FIREWALL')),
    model VARCHAR(100),
    manufacturer VARCHAR(100),
    serial_number VARCHAR(100),
    mac_address VARCHAR(17),
    ip_address INET,
    snmp_community VARCHAR(50),
    snmp_version VARCHAR(10) DEFAULT 'v2c',
    firmware_version VARCHAR(50),
    management_protocol VARCHAR(20) DEFAULT 'SNMP' CHECK (management_protocol IN ('SNMP', 'SSH', 'HTTP', 'WEB_SOCKET')),
    location_id UUID REFERENCES locations(id),
    rack_id UUID REFERENCES racks(id),
    rack_position VARCHAR(20),
    status VARCHAR(20) DEFAULT 'INACTIVE' CHECK (status IN ('ACTIVE', 'INACTIVE', 'MAINTENANCE', 'RETIRED')),
    online_status VARCHAR(20) DEFAULT 'UNKNOWN' CHECK (online_status IN ('ONLINE', 'OFFLINE', 'UNKNOWN', 'MAINTENANCE')),
    last_seen_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    CONSTRAINT unique_device_per_location UNIQUE (device_code, location_id)
);

-- 位置信息表
CREATE TABLE locations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    building VARCHAR(100) NOT NULL,
    floor VARCHAR(20),
    room VARCHAR(100),
    area VARCHAR(100),
    parent_location_id UUID REFERENCES locations(id),
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 机柜信息表
CREATE TABLE racks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(50) NOT NULL,
    location_id UUID NOT NULL REFERENCES locations(id),
    units INTEGER DEFAULT 42,
    max_power DECIMAL(8,2),
    current_power DECIMAL(8,2),
    status VARCHAR(20) DEFAULT 'AVAILABLE' CHECK (status IN ('AVAILABLE', 'FULL', 'MAINTENANCE')),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 设备接口表
CREATE TABLE device_interfaces (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    device_id UUID NOT NULL REFERENCES devices(id) ON DELETE CASCADE,
    interface_name VARCHAR(50) NOT NULL,
    interface_type VARCHAR(20) DEFAULT 'ETHERNET',
    speed BIGINT, -- 接口速率(bps)
    mtu INTEGER,
    description VARCHAR(255),
    admin_status VARCHAR(20) DEFAULT 'UP' CHECK (admin_status IN ('UP', 'DOWN')),
    oper_status VARCHAR(20) DEFAULT 'UNKNOWN' CHECK (oper_status IN ('UP', 'DOWN', 'UNKNOWN')),
    mac_address VARCHAR(17),
    ip_address INET,
    vlan_id INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    CONSTRAINT unique_interface_per_device UNIQUE (device_id, interface_name)
);

-- 设备配置模板表
CREATE TABLE device_config_templates (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    device_type VARCHAR(20) NOT NULL,
    version INTEGER DEFAULT 1,
    config_content JSONB NOT NULL,
    description TEXT,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 设备配置历史表
CREATE TABLE device_config_history (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    device_id UUID NOT NULL REFERENCES devices(id) ON DELETE CASCADE,
    template_id UUID REFERENCES device_config_templates(id),
    config_content JSONB NOT NULL,
    config_version INTEGER,
    deployed_by VARCHAR(100),
    deployed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    rollback_data JSONB,
    status VARCHAR(20) DEFAULT 'DEPLOYED' CHECK (status IN ('DEPLOYING', 'DEPLOYED', 'FAILED', 'ROLLBACK'))
);
```

#### 监控和告警表

```sql
-- 告警规则表
CREATE TABLE alert_rules (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    device_type VARCHAR(20),
    metric_name VARCHAR(50) NOT NULL,
    comparison_operator VARCHAR(10) NOT NULL CHECK (comparison_operator IN ('>', '<', '>=', '<=', '=', '!=')),
    threshold_value DECIMAL(10,2),
    duration_seconds INTEGER DEFAULT 60,
    severity VARCHAR(20) NOT NULL CHECK (severity IN ('CRITICAL', 'MAJOR', 'MINOR', 'WARNING', 'INFO')),
    message_template TEXT NOT NULL,
    enabled BOOLEAN DEFAULT true,
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 告警记录表
CREATE TABLE alerts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    device_id UUID NOT NULL REFERENCES devices(id) ON DELETE CASCADE,
    rule_id UUID REFERENCES alert_rules(id),
    alert_type VARCHAR(50) NOT NULL,
    severity VARCHAR(20) NOT NULL,
    title VARCHAR(255) NOT NULL,
    message TEXT NOT NULL,
    metric_value DECIMAL(10,2),
    threshold_value DECIMAL(10,2),
    current_state VARCHAR(20) NOT NULL DEFAULT 'OPEN' CHECK (current_state IN ('OPEN', 'ACKNOWLEDGED', 'RESOLVED', 'SUPPRESSED')),
    first_occurrence_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    last_occurrence_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    occurrence_count INTEGER DEFAULT 1,
    acknowledged_at TIMESTAMP,
    acknowledged_by VARCHAR(100),
    acknowledged_comment TEXT,
    resolved_at TIMESTAMP,
    resolved_by VARCHAR(100),
    resolved_comment TEXT,
    
    INDEX idx_alerts_device_severity (device_id, severity),
    INDEX idx_alerts_status_time (current_state, last_occurrence_time),
    INDEX idx_alerts_unresolved (current_state, device_id) WHERE current_state IN ('OPEN', 'ACKNOWLEDGED')
);

-- 性能基线表
CREATE TABLE performance_baselines (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    device_id UUID NOT NULL REFERENCES devices(id) ON DELETE CASCADE,
    metric_name VARCHAR(50) NOT NULL,
    baseline_period VARCHAR(20) NOT NULL CHECK (baseline_period IN ('HOURLY', 'DAILY', 'WEEKLY', 'MONTHLY')),
    mean_value DECIMAL(10,2),
    std_deviation DECIMAL(10,2),
    min_value DECIMAL(10,2),
    max_value DECIMAL(10,2),
    p95_value DECIMAL(10,2),
    p99_value DECIMAL(10,2),
    calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    valid_from TIMESTAMP NOT NULL,
    valid_to TIMESTAMP,
    
    CONSTRAINT unique_baseline_per_device_metric UNIQUE (device_id, metric_name, baseline_period, valid_from)
);
```

#### 用户和权限表

```sql
-- 用户表
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    full_name VARCHAR(100),
    password_hash VARCHAR(255) NOT NULL,
    role VARCHAR(20) NOT NULL DEFAULT 'VIEWER' CHECK (role IN ('ADMIN', 'OPERATOR', 'VIEWER')),
    department VARCHAR(100),
    phone VARCHAR(20),
    is_active BOOLEAN DEFAULT true,
    last_login_at TIMESTAMP,
    failed_login_attempts INTEGER DEFAULT 0,
    locked_until TIMESTAMP,
    password_expires_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 权限表
CREATE TABLE permissions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) UNIQUE NOT NULL,
    description TEXT,
    resource VARCHAR(50) NOT NULL,
    action VARCHAR(50) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 角色权限关联表
CREATE TABLE role_permissions (
    role VARCHAR(20) NOT NULL,
    permission_id UUID NOT NULL REFERENCES permissions(id) ON DELETE CASCADE,
    granted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    PRIMARY KEY (role, permission_id)
);

-- 用户会话表
CREATE TABLE user_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    session_token VARCHAR(255) UNIQUE NOT NULL,
    refresh_token VARCHAR(255) UNIQUE,
    device_info JSONB,
    ip_address INET,
    user_agent TEXT,
    expires_at TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_sessions_user (user_id),
    INDEX idx_sessions_token (session_token),
    INDEX idx_sessions_expires (expires_at)
);
```

### 3. 数据湖模型 (Apache Iceberg)

#### 表结构设计

```sql
-- 设备历史指标数据表 (按天分区)
CREATE TABLE device_metrics_iceberg (
    device_id STRING,
    device_type STRING,
    location STRING,
    timestamp TIMESTAMP,
    -- CPU指标
    cpu_usage DOUBLE,
    cpu_load_1min DOUBLE,
    cpu_load_5min DOUBLE,
    cpu_load_15min DOUBLE,
    -- 内存指标
    memory_total BIGINT,
    memory_used BIGINT,
    memory_usage DOUBLE,
    memory_available BIGINT,
    -- 磁盘指标
    disk_devices ARRAY<STRUCT<
        device: STRING,
        total: BIGINT,
        used: BIGINT,
        usage: DOUBLE,
        mount_point: STRING
    >>,
    -- 网络指标
    network_interfaces ARRAY<STRUCT<
        name: STRING,
        rx_bytes: BIGINT,
        tx_bytes: BIGINT,
        rx_packets: BIGINT,
        tx_packets: BIGINT,
        rx_errors: BIGINT,
        tx_errors: BIGINT
    >>,
    -- 环境指标
    temperature_cpu DOUBLE,
    temperature_system DOUBLE,
    power_voltage DOUBLE,
    power_current DOUBLE,
    power_watts DOUBLE,
    -- 设备信息
    uptime BIGINT,
    firmware_version STRING,
    boot_time TIMESTAMP
) 
USING ICEBERG
PARTITIONED BY (days(timestamp))
LOCATION 'hdfs://namenode:8020/warehouse/device_metrics'
TBLPROPERTIES (
    'format-version'='2',
    'write.metadata.compression-codec'='zstd',
    'write.parquet.compression-codec'='zstd'
);

-- 设备告警历史表
CREATE TABLE device_alerts_iceberg (
    alert_id STRING,
    device_id STRING,
    device_type STRING,
    location STRING,
    alert_type STRING,
    severity STRING,
    title STRING,
    message STRING,
    metric_value DOUBLE,
    threshold_value DOUBLE,
    first_occurrence_time TIMESTAMP,
    last_occurrence_time TIMESTAMP,
    occurrence_count INT,
    resolved_time TIMESTAMP,
    resolution STRING
)
USING ICEBERG
PARTITIONED BY (days(last_occurrence_time))
LOCATION 'hdfs://namenode:8020/warehouse/device_alerts';
```

## 数据处理流水线

### 1. 实时数据处理 (Apache Flink)

```java
public class DeviceDataProcessingJob {
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        // 配置Kafka源
        Properties kafkaProps = new Properties();
        kafkaProps.setProperty("bootstrap.servers", "kafka-cluster:9092");
        kafkaProps.setProperty("group.id", "flink-device-processor");
        
        // 设备数据流
        DataStream<DeviceDataMessage> deviceDataStream = env
            .addSource(new FlinkKafkaConsumer<>("device-data-raw", 
                                              new DeviceDataDeserializationSchema(), kafkaProps))
            .name("device-data-source")
            .uid("device-data-source");
        
        // 数据清洗和标准化
        DataStream<StandardizedDeviceData> cleanedDataStream = deviceDataStream
            .process(new DataCleaningProcessFunction())
            .name("data-cleaning")
            .uid("data-cleaning");
        
        // 写入时序数据库
        cleanedDataStream.addSink(new InfluxDBSink<>());
        
        // 告警检测
        DataStream<AlertEvent> alertStream = cleanedDataStream
            .process(new AlertDetectionProcessFunction())
            .name("alert-detection")
            .uid("alert-detection");
        
        // 发送告警通知
        alertStream.addSink(new AlertNotificationSink());
        
        // 实时聚合统计
        DataStream<DeviceMetricsAggregate> aggregatedStream = cleanedDataStream
            .keyBy(data -> data.getDeviceId())
            .timeWindow(Time.minutes(5))
            .aggregate(new MetricsAggregator());
        
        // 写入实时统计表
        aggregatedStream.addSink(new RealTimeStatisticsSink());
        
        // 机器学习特征提取
        cleanedDataStream
            .process(new FeatureExtractionProcessFunction())
            .addSink(new MLFeatureSink());
        
        env.execute("Device Data Processing Job");
    }
}
```

### 2. 批处理分析 (Spark)

```scala
object DeviceAnalyticsBatchJob {
  
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder()
      .appName("DeviceAnalytics")
      .config("spark.sql.adaptive.enabled", "true")
      .config("spark.sql.adaptive.coalescePartitions.enabled", "true")
      .getOrCreate()
    
    import spark.implicits._
    
    // 读取设备历史数据
    val deviceMetricsDF = spark.read
      .format("iceberg")
      .load("warehouse.device_metrics")
      .filter($"timestamp" >= date_sub(current_date(), 30))
    
    // 计算性能基线
    val baselineDF = deviceMetricsDF
      .groupBy("device_id", "device_type", window($"timestamp", "1 day"))
      .agg(
        avg("cpu_usage").as("avg_cpu"),
        stddev("cpu_usage").as("stddev_cpu"),
        avg("memory_usage").as("avg_memory"),
        percentile_approx("cpu_usage", 0.95).as("p95_cpu")
      )
    
    // 保存基线数据
    baselineDF.write
      .mode("overwrite")
      .format("iceberg")
      .save("warehouse.performance_baselines")
    
    // 异常设备分析
    val anomalyDF = deviceMetricsDF
      .join(baselineDF, Seq("device_id", "device_type"))
      .filter($"cpu_usage" > ($"avg_cpu" + 2 * $"stddev_cpu") || 
              $"memory_usage" > ($"avg_memory" + 0.3))
      .select("device_id", "timestamp", "cpu_usage", "memory_usage", "avg_cpu", "stddev_cpu")
    
    anomalyDF.write
      .mode("append")
      .format("iceberg")
      .save("warehouse.device_anomalies")
    
    spark.stop()
  }
}
```

## 数据质量保障

### 1. 数据验证规则

```java
@Component
public class DataValidationService {
    
    public ValidationResult validateDeviceData(DeviceDataMessage message) {
        ValidationResult result = new ValidationResult();
        
        // 必填字段验证
        if (StringUtils.isEmpty(message.getDeviceId())) {
            result.addError("deviceId is required");
        }
        
        // 数值范围验证
        if (message.getMetrics().getCpu().getUsage() < 0 || 
            message.getMetrics().getCpu().getUsage() > 100) {
            result.addError("CPU usage must be between 0 and 100");
        }
        
        // 时间戳验证
        long timeDiff = Math.abs(System.currentTimeMillis() - 
                               message.getTimestamp().getTime());
        if (timeDiff > TimeUnit.MINUTES.toMillis(30)) {
            result.addError("Timestamp is too old or too far in future");
        }
        
        // IP地址格式验证
        if (!InetAddressUtils.isIPv4Address(message.getDeviceId())) {
            result.addWarning("Invalid IP address format");
        }
        
        return result;
    }
    
    public void handleInvalidData(DeviceDataMessage message, ValidationResult result) {
        // 发送数据质量告警
        kafkaTemplate.send("data-quality-alerts", message.getDeviceId(), 
                          JSON.toJSONString(new DataQualityAlert(message, result)));
        
        // 记录错误日志
        log.warn("Invalid device data from {}: {}", message.getDeviceId(), result.getErrors());
        
        // 可选：隔离无效数据或尝试修复
        if (result.isCritical()) {
            quarantineData(message);
        }
    }
}
```

### 2. 数据完整性监控

```sql
-- 数据完整性检查查询
WITH data_completeness AS (
  SELECT 
    device_id,
    COUNT(*) as total_records,
    COUNT(cpu_usage) as cpu_records,
    COUNT(memory_usage) as memory_records,
    COUNT(network_in) as network_records,
    AVG(cpu_usage) as avg_cpu
  FROM device_metrics 
  WHERE timestamp >= NOW() - INTERVAL '1 hour'
  GROUP BY device_id
)
SELECT 
  device_id,
  total_records,
  CASE 
    WHEN total_records = 0 THEN 'NO_DATA'
    WHEN cpu_records < total_records * 0.9 THEN 'MISSING_CPU'
    WHEN memory_records < total_records * 0.9 THEN 'MISSING_MEMORY'
    WHEN network_records < total_records * 0.9 THEN 'MISSING_NETWORK'
    ELSE 'COMPLETE'
  END as data_quality_status
FROM data_completeness
WHERE avg_cpu IS NULL OR avg_cpu < 0 OR avg_cpu > 100;
```

## 总结

本设计方案提供了完整的设备接入和监控数据模型，包含：

1. **多协议设备接入**: 支持SNMP、WebSocket、SSH等多种接入方式
2. **统一数据格式**: 标准化的JSON数据格式，支持所有设备类型
3. **分层数据存储**: 时序数据库(InfluxDB)、关系数据库(PostgreSQL)、数据湖(Iceberg)三层架构
4. **实时批处理**: Flink实时流处理 + Spark批处理分析
5. **数据质量保障**: 完整的数据验证和质量监控机制

该设计可以有效支撑3000+设备的运维监控需求，为可视化大屏系统提供可靠的数据支撑。