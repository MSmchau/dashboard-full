# 可视化大屏数据展示系统后端架构设计

## 架构概述

针对3000+设备（路由器、交换机、AC、AP）的运维场景，设计高可用、高性能、可扩展的微服务后端架构。

### 核心挑战
- **海量设备接入**: 3000+设备并发数据上报
- **实时数据处理**: 毫秒级数据处理和推送
- **多维数据存储**: 支持实时和历史数据分析
- **智能运维**: AI驱动的异常检测和预测性维护

---

## 总体架构设计

```
┌─────────────────────────────────────────────────────────────┐
│                    负载均衡层 (Load Balancer)                 │
│                  Nginx + Keepalived                         │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                      API网关层                               │
│                Spring Cloud Gateway                         │
│           (路由、鉴权、限流、监控)                            │
└─────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    微服务层 (Microservices)                  │
├─────────────────┬─────────────────┬─────────────────────────┤
│  设备管理服务    │   数据采集服务   │    实时计算服务         │
│  Device Service │ Collection Svc  │ Stream Service          │
├─────────────────┼─────────────────┼─────────────────────────┤
│  告警服务        │   历史查询服务   │    AI分析服务          │
│  Alert Service  │  Query Service  │ AI Analysis Svc         │
├─────────────────┼─────────────────┼─────────────────────────┤
│  用户认证服务    │   配置管理服务   │    报告服务            │
│  Auth Service   │   Config Svc    │   Report Svc            │
└─────────────────┴─────────────────┴─────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    数据处理层                                │
├─────────────────┬─────────────────┬─────────────────────────┤
│   消息队列       │   流处理引擎     │    缓存集群            │
│   Apache Kafka  │  Apache Flink   │     Redis Cluster      │
└─────────────────┴─────────────────┴─────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────┐
│                    数据存储层                                │
├─────────────────┬─────────────────┬─────────────────────────┤
│   时序数据库     │    关系数据库    │    对象存储            │
│  InfluxDB/TSDB  │   PostgreSQL    │    MinIO/S3            │
├─────────────────┴─────────────────┴─────────────────────────┤
│                   数据湖 (Data Lake)                        │
│              Apache Iceberg + HDFS/S3                       │
└─────────────────────────────────────────────────────────────┘
```

---

## 核心微服务设计

### 1. 设备管理服务 (Device Service)

**职责**: 设备注册、状态管理、配置下发

**技术栈**: Spring Boot + MyBatis Plus + Redis

**核心功能**:
```java
@RestController
@RequestMapping("/api/devices")
public class DeviceController {
    
    // 设备注册
    @PostMapping("/register")
    public ResponseEntity<DeviceInfo> registerDevice(@RequestBody DeviceRegisterRequest request);
    
    // 设备状态上报
    @PostMapping("/{deviceId}/status")
    public ResponseEntity<Void> updateDeviceStatus(@PathVariable String deviceId, @RequestBody DeviceStatus status);
    
    // 设备配置下发
    @PostMapping("/{deviceId}/config")
    public ResponseEntity<Void> pushConfig(@PathVariable String deviceId, @RequestBody DeviceConfig config);
    
    // 设备列表查询
    @GetMapping
    public ResponseEntity<Page<DeviceInfo>> getDevices(@RequestParam(defaultValue = "1") int page,
                                                       @RequestParam(defaultValue = "20") int size);
}
```

**数据模型**:
```sql
-- 设备基础信息表
CREATE TABLE devices (
    id VARCHAR(64) PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    type VARCHAR(50) NOT NULL, -- router, switch, ac, ap
    model VARCHAR(100),
    ip_address INET,
    mac_address VARCHAR(17),
    location VARCHAR(255),
    status TINYINT DEFAULT 0, -- 0:离线 1:在线 2:异常
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_type_status (type, status),
    INDEX idx_location (location)
);

-- 设备实时状态表
CREATE TABLE device_status (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    device_id VARCHAR(64) NOT NULL,
    cpu_usage DECIMAL(5,2),
    memory_usage DECIMAL(5,2),
    disk_usage DECIMAL(5,2),
    network_in BIGINT,
    network_out BIGINT,
    temperature DECIMAL(5,2),
    uptime BIGINT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_device_time (device_id, timestamp),
    INDEX idx_timestamp (timestamp)
);
```

### 2. 数据采集服务 (Data Collection Service)

**职责**: 接收设备数据上报、数据清洗和格式化

**技术栈**: Spring Boot + Apache Kafka + Redis

**核心功能**:
```java
@Component
public class DeviceDataCollector {
    
    @KafkaListener(topics = "device-data", groupId = "collection-service")
    public void collectDeviceData(ConsumerRecord<String, String> record) {
        try {
            // 数据解析和验证
            DeviceData deviceData = parseDeviceData(record.value());
            
            // 数据清洗
            DeviceData cleanedData = dataCleaner.clean(deviceData);
            
            // 发送到Kafka主题进行流处理
            kafkaTemplate.send("device-data-cleaned", cleanedData.getDeviceId(), 
                              JSON.toJSONString(cleanedData));
            
            // 缓存最新状态到Redis
            redisTemplate.opsForValue().set("device:latest:" + cleanedData.getDeviceId(), 
                                          JSON.toJSONString(cleanedData), Duration.ofMinutes(5));
                                          
        } catch (Exception e) {
            log.error("Failed to collect device data: {}", record.value(), e);
        }
    }
}
```

### 3. 实时计算服务 (Stream Processing Service)

**职责**: 实时数据处理、异常检测、告警触发

**技术栈**: Apache Flink + Apache Kafka

**Flink作业配置**:
```java
public class DeviceDataStreamJob {
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        // 配置Kafka数据源
        Properties kafkaProps = new Properties();
        kafkaProps.setProperty("bootstrap.servers", "kafka-cluster:9092");
        kafkaProps.setProperty("group.id", "flink-stream-processor");
        
        DataStream<DeviceData> deviceDataStream = env
            .addSource(new FlinkKafkaConsumer<>("device-data-cleaned", 
                                              new DeviceDataDeserializationSchema(), kafkaProps))
            .keyBy(DeviceData::getDeviceId)
            .window(TumblingProcessingTimeWindows.of(Time.seconds(10)))
            .aggregate(new DeviceDataAggregator());
        
        // 异常检测
        DataStream<Alert> alertStream = deviceDataStream
            .keyBy(data -> data.getDeviceId())
            .process(new AnomalyDetectionProcessFunction());
        
        // 输出到告警主题
        alertStream.addSink(new FlinkKafkaProducer<>(
            "device-alerts",
            new AlertSerializationSchema(),
            kafkaProps
        ));
        
        env.execute("Device Data Stream Processing Job");
    }
}
```

### 4. 历史查询服务 (Query Service)

**职责**: 历史数据查询、统计分析、报表生成

**技术栈**: Spring Boot + InfluxDB + ClickHouse

**核心API**:
```java
@RestController
@RequestMapping("/api/analytics")
public class AnalyticsController {
    
    @GetMapping("/devices/{deviceId}/metrics")
    public ResponseEntity<List<MetricData>> getDeviceMetrics(
            @PathVariable String deviceId,
            @RequestParam String startTime,
            @RequestParam String endTime,
            @RequestParam(defaultValue = "1m") String interval) {
        
        // 查询InfluxDB时序数据
        Query query = new Query.Builder()
            .database("device_metrics")
            .query("SELECT mean(cpu_usage), mean(memory_usage) FROM device_status " +
                   "WHERE device_id = '" + deviceId + "' AND time > '" + startTime + "' " +
                   "AND time < '" + endTime + "' GROUP BY time(" + interval + ")")
            .build();
        
        QueryResult result = influxDB.query(query);
        return ResponseEntity.ok(parseQueryResult(result));
    }
    
    @GetMapping("/dashboard/overview")
    public ResponseEntity<DashboardOverview> getDashboardOverview() {
        // 聚合查询：设备在线率、告警统计、性能指标
        DashboardOverview overview = dashboardService.getOverview();
        return ResponseEntity.ok(overview);
    }
}
```

### 5. AI分析服务 (AI Analysis Service)

**职责**: 异常检测、预测性维护、根因分析

**技术栈**: Python FastAPI + TensorFlow/PyTorch + Scikit-learn

**核心功能**:
```python
from fastapi import FastAPI, HTTPException
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

app = FastAPI()

class DeviceAnomalyDetector:
    def __init__(self):
        self.model = IsolationForest(contamination=0.1, random_state=42)
        self.scaler = StandardScaler()
        
    def detect_anomaly(self, device_data: DeviceData) -> AnomalyResult:
        # 特征工程
        features = self.extract_features(device_data)
        
        # 异常检测
        is_anomaly = self.model.predict([features])[0] == -1
        anomaly_score = self.model.decision_function([features])[0]
        
        # 根因分析
        root_causes = self.analyze_root_cause(device_data, features)
        
        return AnomalyResult(
            device_id=device_data.device_id,
            is_anomaly=is_anomaly,
            score=anomaly_score,
            root_causes=root_causes,
            timestamp=datetime.utcnow()
        )

@app.post("/api/ai/anomaly-detection")
async def detect_anomaly(request: AnomalyDetectionRequest):
    try:
        detector = DeviceAnomalyDetector()
        result = detector.detect_anomaly(request.device_data)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

## 数据存储架构

### 1. 时序数据存储 (InfluxDB)

**用途**: 设备实时指标数据存储和查询

**设计策略**:
```sql
-- 创建数据库和保留策略
CREATE DATABASE device_metrics WITH 
  DURATION 90d -- 90天数据保留
  REPLICATION 1 
  SHARD DURATION 7d;

-- 创建measurement
CREATE RETENTION POLICY "90_days" ON "device_metrics" DURATION 90d REPLICATION 1 DEFAULT;

-- 创建索引优化查询性能
CREATE INDEX "idx_device_time" ON "device_status" ("device_id", "time");
CREATE INDEX "idx_type_time" ON "device_status" ("type", "time");
```

### 2. 关系数据存储 (PostgreSQL)

**用途**: 设备配置、用户信息、告警记录等

**核心表设计**:
```sql
-- 用户表
CREATE TABLE users (
    id BIGSERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    email VARCHAR(100),
    role VARCHAR(20) DEFAULT 'viewer', -- admin, operator, viewer
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 告警表
CREATE TABLE alerts (
    id BIGSERIAL PRIMARY KEY,
    device_id VARCHAR(64) NOT NULL,
    alert_type VARCHAR(50) NOT NULL,
    severity VARCHAR(20) NOT NULL, -- critical, major, minor, info
    message TEXT NOT NULL,
    status VARCHAR(20) DEFAULT 'open', -- open, acknowledged, resolved
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    resolved_at TIMESTAMP,
    resolved_by BIGINT REFERENCES users(id),
    INDEX idx_device_severity (device_id, severity),
    INDEX idx_status_time (status, created_at)
);

-- 配置模板表
CREATE TABLE config_templates (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    device_type VARCHAR(50) NOT NULL,
    config_content JSONB NOT NULL,
    version INTEGER DEFAULT 1,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 3. 数据湖存储 (Apache Iceberg)

**用途**: 大规模历史数据分析和机器学习

**表结构**:
```sql
-- 创建Iceberg表
CREATE TABLE device_metrics_iceberg (
    device_id STRING,
    timestamp TIMESTAMP,
    cpu_usage DOUBLE,
    memory_usage DOUBLE,
    disk_usage DOUBLE,
    network_in BIGINT,
    network_out BIGINT,
    temperature DOUBLE
)
USING ICEBERG
PARTITIONED BY (days(timestamp))
LOCATION 'hdfs://namenode:8020/warehouse/device_metrics';
```

---

## 消息队列设计

### Apache Kafka 主题规划

| 主题名称 | 用途 | 分区数 | 副本数 | 保留时间 |
|----------|------|--------|--------|----------|
| device-raw-data | 设备原始数据上报 | 12 | 3 | 24小时 |
| device-data-cleaned | 清洗后的设备数据 | 12 | 3 | 7天 |
| device-metrics | 聚合后的指标数据 | 6 | 3 | 30天 |
| device-alerts | 告警事件 | 3 | 3 | 90天 |
| device-config | 配置下发指令 | 3 | 3 | 7天 |

### 生产者和消费者配置

```java
@Configuration
public class KafkaConfig {
    
    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka-cluster:9092");
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        props.put(ProducerConfig.ACKS_CONFIG, "all");
        props.put(ProducerConfig.RETRIES_CONFIG, 3);
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
        props.put(ProducerConfig.LINGER_MS_CONFIG, 5);
        return new DefaultKafkaProducerFactory<>(props);
    }
}
```

---

## 缓存架构设计

### Redis Cluster 配置

**节点规划**:
- 3个主节点 + 3个从节点
- 每个节点配置8GB内存
- 启用RDB + AOF持久化

**缓存策略**:
```java
@Service
public class CacheService {
    
    // 设备最新状态缓存 (5分钟)
    private static final String DEVICE_LATEST_PREFIX = "device:latest:";
    private static final Duration DEVICE_LATEST_TTL = Duration.ofMinutes(5);
    
    // 用户会话缓存 (30分钟)
    private static final String USER_SESSION_PREFIX = "user:session:";
    private static final Duration USER_SESSION_TTL = Duration.ofMinutes(30);
    
    // 仪表盘数据缓存 (1分钟)
    private static final String DASHBOARD_DATA_PREFIX = "dashboard:data:";
    private static final Duration DASHBOARD_DATA_TTL = Duration.ofMinutes(1);
    
    public void cacheDeviceLatestStatus(String deviceId, DeviceStatus status) {
        String key = DEVICE_LATEST_PREFIX + deviceId;
        redisTemplate.opsForValue().set(key, JSON.toJSONString(status), DEVICE_LATEST_TTL);
    }
}
```

---

## 安全架构设计

### 认证和授权

**JWT Token 策略**:
```java
@Component
public class JwtTokenProvider {
    
    private final String jwtSecret = "your-secret-key";
    private final int jwtExpirationInMs = 86400000; // 24小时
    
    public String generateToken(UserDetails userPrincipal) {
        Date now = new Date();
        Date expiryDate = new Date(now.getTime() + jwtExpirationInMs);
        
        return Jwts.builder()
                .setSubject(userPrincipal.getUsername())
                .claim("roles", userPrincipal.getAuthorities())
                .setIssuedAt(now)
                .setExpiration(expiryDate)
                .signWith(SignatureAlgorithm.HS512, jwtSecret)
                .compact();
    }
}
```

**API 权限控制**:
```java
@RestController
@RequestMapping("/api/devices")
@PreAuthorize("hasRole('OPERATOR') or hasRole('ADMIN')")
public class DeviceController {
    
    @GetMapping
    @PreAuthorize("hasAuthority('DEVICE_READ')")
    public ResponseEntity<Page<DeviceInfo>> getDevices() {
        // 设备列表查询
    }
    
    @PostMapping("/{deviceId}/config")
    @PreAuthorize("hasAuthority('DEVICE_CONFIG')")
    public ResponseEntity<Void> pushConfig(@PathVariable String deviceId) {
        // 配置下发
    }
}
```

### 网络安全

**API 网关限流**:
```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: device-service
          uri: lb://device-service
          predicates:
            - Path=/api/devices/**
          filters:
            - name: RequestRateLimiter
              args:
                redis-rate-limiter.replenishRate: 10  # 每秒10个请求
                redis-rate-limiter.burstCapacity: 50  # 突发50个请求
```

---

## 监控和运维

### Prometheus + Grafana 监控体系

**关键指标**:
- 系统指标: CPU、内存、磁盘、网络
- 应用指标: 接口响应时间、错误率、吞吐量
- 业务指标: 设备在线率、告警数量、数据延迟

**Prometheus 配置**:
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'device-service'
    static_configs:
      - targets: ['device-service:8080']
    metrics_path: '/actuator/prometheus'
    
  - job_name: 'data-collection-service'
    static_configs:
      - targets: ['data-collection-service:8080']
```

### 日志管理 (ELK Stack)

**Elasticsearch 索引策略**:
```json
{
  "index_patterns": ["device-logs-*"],
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "index.lifecycle.name": "device-logs-policy",
    "index.lifecycle.rollover_alias": "device-logs"
  },
  "mappings": {
    "properties": {
      "timestamp": {
        "type": "date"
      },
      "device_id": {
        "type": "keyword"
      },
      "level": {
        "type": "keyword"
      },
      "message": {
        "type": "text"
      }
    }
  }
}
```

---

## 部署架构

### Kubernetes 部署配置

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: device-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: device-service
  template:
    metadata:
      labels:
        app: device-service
    spec:
      containers:
      - name: device-service
        image: device-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "production"
        - name: REDIS_URL
          value: "redis://redis-cluster:6379"
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "kafka-cluster:9092"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 30
```

### 数据库高可用配置

**PostgreSQL 主从复制**:
```yaml
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: device-postgres
spec:
  instances: 3
  primaryUpdateStrategy: unsupervised
  
  postgresql:
    parameters:
      max_connections: "200"
      shared_buffers: "256MB"
      
  bootstrap:
    initdb:
      database: device_mgmt
      owner: device_admin
```

---

## 性能优化策略

### 1. 数据库优化

**索引策略**:
```sql
-- 复合索引优化查询
CREATE INDEX CONCURRENTLY idx_device_status_composite 
ON device_status(device_id, timestamp, cpu_usage) 
WHERE timestamp > NOW() - INTERVAL '30 days';

-- 分区表优化
CREATE TABLE device_status_y2024m01 PARTITION OF device_status
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

### 2. 缓存优化

**多级缓存**:
- L1: 应用本地缓存 (Caffeine) - 1分钟
- L2: Redis分布式缓存 - 5分钟
- L3: 数据库查询缓存 - 30分钟

### 3. 流处理优化

**Flink 调优**:
```java
// 开启增量检查点
env.enableCheckpointing(5000); // 5秒一次
env.getCheckpointConfig().setCheckpointTimeout(60000); // 60秒超时

// 设置并行度
env.setParallelism(12);

// 开启反压处理
env.getCheckpointConfig().setPreferCheckpointForRecovery(true);
```

---

## 总结

该后端架构具备以下特点：

1. **高可用性**: 微服务 + 集群部署，无单点故障
2. **高性能**: 异步处理 + 缓存优化，支持万级并发
3. **可扩展性**: 容器化部署，支持水平扩展
4. **易维护性**: 完善的监控、日志和告警体系
5. **安全性**: 多层安全防护，符合企业级安全要求

通过该架构设计，可以有效支撑3000+设备的运维管理需求，为可视化大屏系统提供稳定可靠的后端支撑。