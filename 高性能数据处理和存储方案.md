# 高性能数据处理和存储方案

## 概述

针对3000+设备的高频数据采集、实时处理和存储需求，设计高性能的数据处理流水线和高可用存储架构。

## 数据处理性能目标

### 关键性能指标 (KPI)

| 指标类型 | 目标值 | 说明 |
|----------|--------|------|
| 数据处理吞吐量 | 10万条/秒 | 设备数据实时处理能力 |
| 端到端延迟 | < 3秒 | 从数据采集到可视化展示 |
| 系统可用性 | 99.9% | 年度停机时间 < 8.76小时 |
| 并发设备连接 | 5000+ | 支持设备峰值连接 |
| 数据查询响应 | < 500ms | 95%查询在500ms内返回 |
| 存储写入性能 | 5万条/秒 | 写入InfluxDB性能 |

## 高性能数据处理架构

### 1. 流处理优化 (Apache Flink)

#### Flink 集群配置优化

```yaml
# flink-config.yaml
# JVM堆内存优化
env.java.opts: "-Xmx32g -Xms32g -XX:+UseG1GC -XX:MaxGCPauseMillis=20"

# 并行度配置
parallelism.default: 24
taskmanager.numberOfTaskSlots: 4
taskmanager.memory.process.size: 8gb

# 检查点优化
execution.checkpointing.interval: 10000
execution.checkpointing.mode: EXACTLY_ONCE
execution.checkpointing.timeout: 600000
execution.checkpointing.min-pause: 5000

# 反压处理
pipeline.auto-watermark-interval: 200ms
pipeline.max-parallelism: 128
```

#### 高性能数据流处理

```java
@Component
public class OptimizedDeviceDataProcessor {
    
    // 使用批量处理提升性能
    @ProcessElement
    public void processElement(StreamRecord<DeviceDataMessage> element, Context ctx, 
                             Collector<ProcessedDeviceData> out) throws Exception {
        
        DeviceDataMessage message = element.getValue();
        
        // 批量累积数据进行聚合
        if (batchAccumulator.shouldProcessBatch()) {
            List<DeviceDataMessage> batch = batchAccumulator.getBatch();
            List<ProcessedDeviceData> processedBatch = processBatch(batch);
            processedBatch.forEach(out::collect);
            batchAccumulator.clear();
        } else {
            batchAccumulator.add(message);
        }
    }
    
    private List<ProcessedDeviceData> processBatch(List<DeviceDataMessage> batch) {
        return batch.parallelStream()
            .map(this::processSingleMessage)
            .filter(Objects::nonNull)
            .collect(Collectors.toList());
    }
    
    // 使用对象池减少GC压力
    private ProcessedDeviceData processSingleMessage(DeviceDataMessage message) {
        ProcessedDeviceData result = objectPool.borrowObject();
        try {
            result.setDeviceId(message.getDeviceId());
            result.setTimestamp(message.getTimestamp());
            result.setCpuUsage(message.getMetrics().getCpu().getUsage());
            result.setMemoryUsage(message.getMetrics().getMemory().getUsage());
            
            // 复杂计算逻辑
            calculateAnomalyScore(result, message);
            
            return result;
        } catch (Exception e) {
            objectPool.returnObject(result);
            throw new RuntimeException("Processing failed for device: " + message.getDeviceId(), e);
        }
    }
}

// 批量累加器
public class BatchAccumulator {
    private static final int BATCH_SIZE = 1000;
    private final List<DeviceDataMessage> batch = new ArrayList<>();
    
    public void add(DeviceDataMessage message) {
        synchronized (batch) {
            batch.add(message);
        }
    }
    
    public boolean shouldProcessBatch() {
        synchronized (batch) {
            return batch.size() >= BATCH_SIZE;
        }
    }
    
    public List<DeviceDataMessage> getBatch() {
        synchronized (batch) {
            List<DeviceDataMessage> currentBatch = new ArrayList<>(batch);
            batch.clear();
            return currentBatch;
        }
    }
}
```

#### 内存管理优化

```java
@Configuration
public class FlinkMemoryConfig {
    
    @Bean
    public MemoryStateBackend memoryStateBackend() {
        // 使用 RocksDB 状态后端，减少内存使用
        return new RocksDBStateBackend("hdfs://namenode:8020/flink/checkpoints", true);
    }
    
    @Bean
    public FsStateBackend fsStateBackend() {
        return new FsStateBackend("hdfs://namenode:8020/flink/checkpoints", true);
    }
}
```

### 2. 消息队列优化 (Apache Kafka)

#### Kafka 集群配置优化

```yaml
# server.properties
# 基础配置
broker.id=0
listeners=PLAINTEXT://kafka-server:9092
num.network.threads=8
num.io.threads=16
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600

# 存储优化
log.dirs=/data/kafka-logs
num.partitions=12
default.replication.factor=3
min.insync.replicas=2

# 性能优化
log.segment.bytes=1073741824
log.retention.hours=168
log.retention.bytes=1073741824
log.retention.check.interval.ms=300000
log.cleanup.policy=delete

# 压缩配置
compression.type=lz4
log.compaction.enabled=true
log.cleaner.threads=2
```

#### 生产者性能优化

```java
@Configuration
public class KafkaProducerConfig {
    
    @Bean
    public ProducerFactory<String, String> optimizedProducerFactory() {
        Properties props = new Properties();
        
        // 基本配置
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka-cluster:9092");
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class.getName());
        
        // 性能优化配置
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, 65536);          // 批处理大小
        props.put(ProducerConfig.LINGER_MS_CONFIG, 5);               // 等待时间
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 67108864);    // 缓冲区大小
        props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "lz4");    // 压缩算法
        
        // 可靠性配置
        props.put(ProducerConfig.ACKS_CONFIG, "all");                // 确认策略
        props.put(ProducerConfig.RETRIES_CONFIG, 3);                 // 重试次数
        props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5);
        
        // 序列化优化
        props.put(ProducerConfig.MAX_REQUEST_SIZE_CONFIG, 1048576);   // 1MB
        props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 30000);
        
        return new DefaultKafkaProducerFactory<>(props);
    }
}

@Service
public class OptimizedDeviceDataProducer {
    
    private final KafkaTemplate<String, String> kafkaTemplate;
    private final Counter batchSizeCounter;
    private final Timer sendTimer;
    
    public OptimizedDeviceDataProducer(KafkaTemplate<String, String> kafkaTemplate,
                                     Counter batchSizeCounter, Timer sendTimer) {
        this.kafkaTemplate = kafkaTemplate;
        this.batchSizeCounter = batchSizeCounter;
        this.sendTimer = sendTimer;
    }
    
    public void sendDeviceDataBatch(List<DeviceDataMessage> batch) {
        Timer.Sample sample = Timer.start(Metrics.globalRegistry);
        
        try {
            List<Future<RecordMetadata>> futures = batch.stream()
                .map(message -> kafkaTemplate.send("device-data-raw", 
                                                 message.getDeviceId(),
                                                 JSON.toJSONString(message)))
                .collect(Collectors.toList());
            
            // 批量等待所有发送完成
            CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]))
                .get(30, TimeUnit.SECONDS);
                
            batchSizeCounter.increment(batch.size());
            
        } catch (Exception e) {
            log.error("Failed to send device data batch", e);
            metricsCounter.increment("batch.send.errors");
        } finally {
            sample.stop(sendTimer);
        }
    }
}
```

#### 消费者性能优化

```java
@Configuration
public class KafkaConsumerConfig {
    
    @Bean
    public ConsumerFactory<String, String> optimizedConsumerFactory() {
        Properties props = new Properties();
        
        // 基本配置
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka-cluster:9092");
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "device-processor-group");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class.getName());
        
        // 性能优化
        props.put(ConsumerConfig.FETCH_MIN_BYTES_CONFIG, 1024 * 1024);  // 1MB
        props.put(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, 500);
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);         // 单次拉取记录数
        props.put(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG, 1048576); // 1MB
        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10000);
        props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 3000);
        
        // 自动提交优化
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);     // 手动提交
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 5000);
        
        return new DefaultKafkaConsumerFactory<>(props);
    }
}
```

## 高性能存储架构

### 1. 时序数据库优化 (InfluxDB)

#### InfluxDB 集群配置

```yaml
# influxdb.conf
[meta]
  dir = "/var/lib/influxdb/meta"

[data]
  dir = "/var/lib/influxdb/data"
  wal-dir = "/var/lib/influxdb/wal"
  cache-max-memory-size = 1073741824
  cache-snapshot-memory-size = 262144000
  cache-snapshot-write-cold-duration = "10m"
  compact-full-write-cold-duration = "4h"
  max-concurrent-compactions = 4
  max-index-log-file-size = 1048576

[http]
  bind-address = ":8086"
  max-body-size = 25000000
  max-row-limit = 10000

[cluster]
  write-timeout = "10s"
  copy-shard-timeout = "10s"

[retention]
  enabled = true
  check-interval = "30m"
```

#### 数据库分片策略

```sql
-- 创建数据库和保留策略
CREATE DATABASE device_metrics 
WITH 
  DURATION 90d 
  REPLICATION 3 
  SHARD DURATION 7d;

-- 创建复合保留策略
CREATE RETENTION POLICY "raw_data_7d" ON "device_metrics" DURATION 7d REPLICATION 3;
CREATE RETENTION POLICY "hourly_aggr_30d" ON "device_metrics" DURATION 30d REPLICATION 3;
CREATE RETENTION POLICY "daily_aggr_1y" ON "device_metrics" DURATION 365d REPLICATION 3;

-- 创建数据聚合连续查询
CREATE CONTINUOUS QUERY cpu_hourly_avg ON device_metrics
BEGIN
  SELECT mean(cpu_usage) AS avg_cpu_usage
  INTO device_metrics.autogen.cpu_hourly_aggr
  FROM device_metrics.autogen.device_status
  GROUP BY time(1h), device_id
END;

CREATE CONTINUOUS QUERY memory_daily_max ON device_metrics
BEGIN
  SELECT max(memory_usage) AS max_memory_usage
  INTO device_metrics.autogen.memory_daily_aggr
  FROM device_metrics.autogen.device_status
  GROUP BY time(1d), device_id
END;
```

#### 数据写入优化

```java
@Service
public class OptimizedInfluxDBWriter {
    
    private final InfluxDBClient influxDBClient;
    private final WriteApi writeApi;
    private final AsyncWriteApi asyncWriteApi;
    
    // 批量写入优化
    public void writeDeviceMetricsBatch(List<DeviceMetricPoint> points) {
        // 异步批量写入
        points.forEach(point -> {
            Point metricPoint = Point.measurement("device_status")
                .time(point.getTimestamp(), TimeUnit.MILLISECONDS)
                .tag("device_id", point.getDeviceId())
                .tag("device_type", point.getDeviceType())
                .tag("location", point.getLocation())
                .addField("cpu_usage", point.getCpuUsage())
                .addField("memory_usage", point.getMemoryUsage())
                .addField("disk_usage", point.getDiskUsage())
                .addField("network_in", point.getNetworkIn())
                .addField("network_out", point.getNetworkOut())
                .addField("temperature", point.getTemperature());
            
            asyncWriteApi.writePoint("device_metrics", "autogen", metricPoint);
        });
    }
    
    // 高频数据写入优化
    public void writeHighFrequencyData(String deviceId, DeviceMetrics metrics) {
        // 使用WriteOptions进行批量配置
        WriteOptions writeOptions = WriteOptions.builder()
            .batchSize(5000)                    // 批量大小
            .flushInterval(1000)               // 刷新间隔
            .bufferLimit(10000000)             // 缓冲区限制
            .retryInterval(100)                // 重试间隔
            .maxRetries(3)                     // 最大重试
            .jitterInterval(50)                // 抖动间隔
            .build();
        
        try (WriteApi writeApi = influxDBClient.makeWriteApi(writeOptions)) {
            Point point = Point.measurement("device_highfreq")
                .time(System.currentTimeMillis(), TimeUnit.MILLISECONDS)
                .tag("device_id", deviceId)
                .addField("packet_in", metrics.getNetworkInPackets())
                .addField("packet_out", metrics.getNetworkOutPackets())
                .addField("errors_in", metrics.getNetworkInErrors())
                .addField("errors_out", metrics.getNetworkOutErrors())
                .build();
                
            writeApi.writePoint("device_metrics", "autogen", point);
        }
    }
}
```

#### 查询优化

```java
@Service
public class OptimizedInfluxDBQuery {
    
    public List<DeviceMetrics> getDeviceMetricsRange(String deviceId, 
                                                    Instant startTime, 
                                                    Instant endTime) {
        String query = String.format(
            "SELECT cpu_usage, memory_usage, disk_usage, network_in, network_out " +
            "FROM device_status " +
            "WHERE device_id = '%s' AND time >= '%s' AND time < '%s' " +
            "ORDER BY time",
            deviceId, 
            startTime.toString(), 
            endTime.toString()
        );
        
        QueryResult result = influxDBClient.getQueryApi()
            .query(query, "device_metrics");
            
        return parseQueryResult(result);
    }
    
    // 预聚合查询
    public List<DeviceMetricsAggregate> getAggregatedMetrics(String deviceId, 
                                                           String interval) {
        String query = String.format(
            "SELECT mean(cpu_usage) AS avg_cpu, mean(memory_usage) AS avg_memory " +
            "FROM device_status " +
            "WHERE device_id = '%s' AND time >= now() - 1d " +
            "GROUP BY time(%s) " +
            "ORDER BY time",
            deviceId, interval
        );
        
        QueryResult result = influxDBClient.getQueryApi()
            .query(query, "device_metrics");
            
        return parseAggregatedResult(result);
    }
    
    // 并行查询多个设备
    public Map<String, List<DeviceMetrics>> getMultipleDevicesMetrics(
            Set<String> deviceIds, Instant startTime, Instant endTime) {
        
        return deviceIds.parallelStream()
            .collect(Collectors.toMap(
                deviceId -> deviceId,
                deviceId -> getDeviceMetricsRange(deviceId, startTime, endTime)
            ));
    }
}
```

### 2. 关系数据库优化 (PostgreSQL)

#### PostgreSQL 性能配置

```sql
-- postgresql.conf 关键配置
shared_buffers = 8GB
effective_cache_size = 24GB
maintenance_work_mem = 2GB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 1000
random_page_cost = 1.1
effective_io_concurrency = 200

-- 允许更多连接
max_connections = 200

-- 并行查询优化
max_parallel_workers = 8
max_parallel_workers_per_gather = 4
parallel_tuple_cost = 0.1
parallel_setup_cost = 1000.0

-- WAL 配置
wal_level = replica
max_wal_senders = 10
wal_keep_size = 1GB
synchronous_commit = off  -- 提升写入性能
```

#### 索引优化策略

```sql
-- 复合索引优化查询
CREATE INDEX CONCURRENTLY idx_devices_type_status_location 
ON devices(type, status, location_id);

CREATE INDEX CONCURRENTLY idx_device_status_device_time 
ON device_status(device_id, timestamp DESC);

CREATE INDEX CONCURRENTLY idx_alerts_device_severity_status_time 
ON alerts(device_id, severity, current_state, last_occurrence_time DESC);

-- 分区索引优化
CREATE INDEX CONCURRENTLY idx_device_status_partitioned 
ON device_status_y2024m01(device_id, timestamp);

-- 表达式索引
CREATE INDEX CONCURRENTLY idx_devices_ip_pattern 
ON devices USING btree ((ip_address::inet), status) 
WHERE status = 'ACTIVE';

-- JSONB 字段索引
CREATE INDEX CONCURRENTLY idx_device_config_metadata 
ON device_config_history USING gin (config_content);

-- 部分索引
CREATE INDEX CONCURRENTLY idx_active_devices_only 
ON devices(id, name, ip_address) 
WHERE status = 'ACTIVE';
```

#### 分区表设计

```sql
-- 按时间分区设备状态表
CREATE TABLE device_status (
    id BIGSERIAL,
    device_id UUID NOT NULL,
    cpu_usage DECIMAL(5,2),
    memory_usage DECIMAL(5,2),
    disk_usage DECIMAL(5,2),
    network_in BIGINT,
    network_out BIGINT,
    temperature DECIMAL(5,2),
    timestamp TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (timestamp);

-- 创建月度分区
CREATE TABLE device_status_2024_01 PARTITION OF device_status
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE device_status_2024_02 PARTITION OF device_status
FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');

-- 创建自动分区函数
CREATE OR REPLACE FUNCTION create_monthly_partition(table_name text, target_date date)
RETURNS text AS $$
DECLARE
    partition_name text;
    start_date date;
    end_date date;
BEGIN
    -- 计算分区日期范围
    start_date := date_trunc('month', target_date);
    end_date := start_date + interval '1 month';
    partition_name := table_name || '_' || to_char(target_date, 'YYYY_MM');
    
    -- 执行分区创建
    EXECUTE format('CREATE TABLE IF NOT EXISTS %I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',
                   partition_name, table_name, start_date, end_date);
    
    RETURN partition_name;
END;
$$ LANGUAGE plpgsql;

-- 自动分区管理函数
CREATE OR REPLACE FUNCTION manage_device_status_partitions()
RETURNS void AS $$
DECLARE
    target_date date := CURRENT_DATE;
    partition_name text;
    i integer;
BEGIN
    -- 创建未来3个月的分区
    FOR i IN 0..2 LOOP
        target_date := date_trunc('month', CURRENT_DATE + (i || ' months')::interval);
        SELECT create_monthly_partition('device_status', target_date) INTO partition_name;
        
        -- 删除3个月前的分区
        IF i > 2 THEN
            EXECUTE format('DROP TABLE IF EXISTS %I', 
                          'device_status_' || to_char(target_date - interval '3 months', 'YYYY_MM'));
        END IF;
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```

#### 查询优化

```java
@Service
public class OptimizedDeviceQuery {
    
    @Query(nativeQuery = true, value = """
        SELECT d.id, d.name, d.type, d.ip_address, d.online_status,
               ds.cpu_usage, ds.memory_usage, ds.timestamp
        FROM devices d
        JOIN device_status ds ON d.id = ds.device_id
        WHERE d.status = 'ACTIVE' 
          AND d.type = :deviceType
          AND ds.timestamp >= :startTime
          AND ds.timestamp < :endTime
        ORDER BY ds.timestamp DESC
        LIMIT :limit
        """)
    public List<DeviceStatusDTO> getActiveDevicesWithMetrics(
            @Param("deviceType") String deviceType,
            @Param("startTime") Instant startTime,
            @Param("endTime") Instant endTime,
            @Param("limit") int limit);
    
    // 使用分页优化大数据量查询
    @Query(nativeQuery = true, value = """
        SELECT * FROM (
            SELECT d.*, ROW_NUMBER() OVER (ORDER BY d.created_at DESC) as rn
            FROM devices d
            WHERE d.status = 'ACTIVE'
        ) t 
        WHERE rn BETWEEN :offset AND :offset + :limit - 1
        """)
    public List<Device> getDevicesWithPagination(
            @Param("offset") int offset,
            @Param("limit") int limit);
    
    // 批量操作优化
    @Modifying
    @Query(nativeQuery = true, value = """
        UPDATE devices 
        SET online_status = :status, updated_at = CURRENT_TIMESTAMP
        WHERE id = ANY(:deviceIds)
        """)
    public void updateDeviceStatusBatch(@Param("deviceIds") Set<UUID> deviceIds,
                                       @Param("status") String status);
}
```

### 3. 缓存系统优化 (Redis Cluster)

#### Redis Cluster 配置

```conf
# redis-node.conf
port 7000
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 15000
cluster-require-full-coverage no

# 内存优化
maxmemory 6gb
maxmemory-policy allkeys-lru

# 持久化优化
save 900 1
save 300 10
save 60 10000
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes

# 网络优化
tcp-keepalive 300
timeout 0

# 慢查询优化
slowlog-log-slower-than 10000
slowlog-max-len 128
```

#### 缓存架构设计

```java
@Configuration
public class MultiLevelCacheConfig {
    
    // L1: 应用本地缓存 (Caffeine)
    @Bean
    public Cache<String, DeviceInfo> deviceInfoCache() {
        return Caffeine.newBuilder()
            .maximumSize(10000)
            .expireAfterWrite(5, TimeUnit.MINUTES)
            .expireAfterAccess(2, TimeUnit.MINUTES)
            .recordStats()
            .build();
    }
    
    // L2: Redis分布式缓存
    @Bean
    public RedisTemplate<String, Object> redisTemplate() {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        
        Jackson2JsonRedisSerializer<Object> serializer = 
            new Jackson2JsonRedisSerializer<>(Object.class);
        template.setDefaultSerializer(serializer);
        
        // 设置连接工厂
        template.setConnectionFactory(redisConnectionFactory());
        
        return template;
    }
}

@Service
public class MultiLevelCacheService {
    
    @Autowired
    @Qualifier("deviceInfoCache")
    private Cache<String, DeviceInfo> l1Cache;
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    private static final String L2_CACHE_PREFIX = "device:info:";
    
    public DeviceInfo getDeviceInfo(String deviceId) {
        // L1 缓存查询
        DeviceInfo deviceInfo = l1Cache.getIfPresent(deviceId);
        if (deviceInfo != null) {
            return deviceInfo;
        }
        
        // L2 缓存查询
        String l2Key = L2_CACHE_PREFIX + deviceId;
        deviceInfo = (DeviceInfo) redisTemplate.opsForValue().get(l2Key);
        if (deviceInfo != null) {
            // 回填 L1 缓存
            l1Cache.put(deviceId, deviceInfo);
            return deviceInfo;
        }
        
        // 数据库查询
        deviceInfo = databaseService.getDeviceInfo(deviceId);
        if (deviceInfo != null) {
            // 同时更新 L1 和 L2 缓存
            l1Cache.put(deviceId, deviceInfo);
            redisTemplate.opsForValue().set(l2Key, deviceInfo, Duration.ofMinutes(10));
        }
        
        return deviceInfo;
    }
    
    // 缓存预热
    @Scheduled(fixedRate = 3600000) // 每小时执行一次
    public void warmUpCache() {
        List<String> criticalDeviceIds = deviceService.getCriticalDeviceIds();
        
        criticalDeviceIds.parallelStream().forEach(deviceId -> {
            DeviceInfo deviceInfo = databaseService.getDeviceInfo(deviceId);
            if (deviceInfo != null) {
                l1Cache.put(deviceId, deviceInfo);
                String l2Key = L2_CACHE_PREFIX + deviceId;
                redisTemplate.opsForValue().set(l2Key, deviceInfo, Duration.ofMinutes(30));
            }
        });
    }
}
```

#### 缓存一致性保障

```java
@Service
public class CacheConsistencyService {
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    @Autowired
    private DeviceRepository deviceRepository;
    
    @Transactional
    public void updateDeviceInfo(String deviceId, DeviceInfo updatedInfo) {
        try {
            // 数据库更新
            deviceRepository.save(updatedInfo);
            
            // 清除缓存
            evictDeviceCache(deviceId);
            
            // 异步更新缓存
            CompletableFuture.runAsync(() -> {
                String l2Key = L2_CACHE_PREFIX + deviceId;
                redisTemplate.opsForValue().set(l2Key, updatedInfo, Duration.ofMinutes(10));
            });
            
        } catch (Exception e) {
            log.error("Failed to update device info with cache consistency", e);
            throw new BusinessException("设备信息更新失败", e);
        }
    }
    
    private void evictDeviceCache(String deviceId) {
        // 清除 L1 缓存 (通过缓存管理器)
        cacheManager.getCache("deviceInfoCache").evict(deviceId);
        
        // 清除 L2 缓存
        String l2Key = L2_CACHE_PREFIX + deviceId;
        redisTemplate.delete(l2Key);
    }
    
    // 监听数据库变更，清理缓存
    @EventListener
    @Async
    public void handleDeviceUpdateEvent(DeviceUpdateEvent event) {
        String deviceId = event.getDeviceId();
        evictDeviceCache(deviceId);
        
        // 发布缓存失效事件
        applicationEventPublisher.publishEvent(
            new DeviceCacheInvalidatedEvent(deviceId)
        );
    }
}
```

## 数据压缩和归档

### 1. 数据压缩策略

```java
@Component
public class DataCompressionService {
    
    // 使用LZ4压缩算法优化网络传输
    public byte[] compressWithLZ4(byte[] data) {
        return LZ4Factory.fastestInstance().fastCompressor().compress(data);
    }
    
    // 数据分级压缩
    public void archiveOldData(LocalDateTime cutoffDate) {
        List<String> deviceIds = deviceService.getAllDeviceIds();
        
        deviceIds.parallelStream().forEach(deviceId -> {
            // 查询3个月前的数据
            Instant startTime = cutoffDate.minusMonths(3).toInstant(ZoneOffset.UTC);
            Instant endTime = cutoffDate.toInstant(ZoneOffset.UTC);
            
            List<DeviceMetricPoint> oldData = 
                timeSeriesService.getDeviceData(deviceId, startTime, endTime);
            
            if (!oldData.isEmpty()) {
                // 压缩数据
                byte[] compressedData = compressDeviceData(oldData);
                
                // 存储到冷数据存储
                coldStorageService.storeCompressedData(deviceId, compressedData);
                
                // 从热存储删除
                timeSeriesService.deleteDataRange(deviceId, startTime, endTime);
            }
        });
    }
    
    private byte[] compressDeviceData(List<DeviceMetricPoint> data) {
        // 序列化数据
        byte[] serializedData = JSON.toJSONBytes(data);
        
        // 压缩
        return compressWithLZ4(serializedData);
    }
}
```

### 2. 数据归档策略

```sql
-- 创建归档表
CREATE TABLE device_metrics_archive (
    device_id VARCHAR(64),
    archive_month DATE,
    data_file_path TEXT,
    compressed_size BIGINT,
    original_size BIGINT,
    record_count INTEGER,
    archived_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    PRIMARY KEY (device_id, archive_month)
);

-- 定期归档查询
CREATE OR REPLACE FUNCTION archive_device_metrics()
RETURNS void AS $$
DECLARE
    archive_date DATE := date_trunc('month', CURRENT_DATE - interval '3 months');
    device_record RECORD;
BEGIN
    FOR device_record IN 
        SELECT DISTINCT device_id FROM device_status 
        WHERE timestamp < archive_date
    LOOP
        -- 导出数据到文件
        COPY (
            SELECT * FROM device_status 
            WHERE device_id = device_record.device_id 
            AND timestamp < archive_date
        ) TO PROGRAM 'gzip > /archive/' || device_record.device_id || '_' || 
          to_char(archive_date, 'YYYY_MM') || '.csv.gz' CSV HEADER;
          
        -- 记录归档信息
        INSERT INTO device_metrics_archive (device_id, archive_month, 
                                          data_file_path, original_size, record_count)
        VALUES (
            device_record.device_id,
            archive_date,
            '/archive/' || device_record.device_id || '_' || 
                to_char(archive_date, 'YYYY_MM') || '.csv.gz',
            0,  -- 需要通过外部程序获取实际文件大小
            0   -- 需要通过外部程序获取实际记录数
        );
        
        -- 删除已归档数据
        DELETE FROM device_status 
        WHERE device_id = device_record.device_id 
        AND timestamp < archive_date;
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```

## 监控和性能调优

### 1. 性能监控

```java
@Component
public class PerformanceMonitor {
    
    private final MeterRegistry meterRegistry;
    private final Counter dataProcessingCounter;
    private final Timer dataProcessingTimer;
    private final Gauge activeConnectionsGauge;
    
    public PerformanceMonitor(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
        this.dataProcessingCounter = Counter.builder("device.data.processed")
            .description("Number of device data records processed")
            .register(meterRegistry);
            
        this.dataProcessingTimer = Timer.builder("device.data.processing.time")
            .description("Time taken to process device data")
            .register(meterRegistry);
            
        this.activeConnectionsGauge = Gauge.builder("device.connections.active")
            .description("Number of active device connections")
            .register(meterRegistry, this, PerformanceMonitor::getActiveConnections);
    }
    
    @EventListener
    public void handleDataProcessed(DataProcessedEvent event) {
        dataProcessingCounter.increment();
        dataProcessingTimer.record(event.getProcessingTime(), TimeUnit.MILLISECONDS);
    }
    
    private double getActiveConnections() {
        return deviceConnectionManager.getActiveConnections();
    }
    
    @Scheduled(fixedRate = 60000) // 每分钟检查一次
    public void checkSystemHealth() {
        Map<String, Object> healthMetrics = collectHealthMetrics();
        
        // 记录关键指标
        gaugeRegistry.gauge("system.cpu.usage", healthMetrics.get("cpu"));
        gaugeRegistry.gauge("system.memory.usage", healthMetrics.get("memory"));
        gaugeRegistry.gauge("database.connections.active", healthMetrics.get("dbConnections"));
        
        // 检查告警阈值
        checkPerformanceThresholds(healthMetrics);
    }
    
    private void checkPerformanceThresholds(Map<String, Object> metrics) {
        double cpuUsage = (Double) metrics.get("cpu");
        double memoryUsage = (Double) metrics.get("memory");
        
        if (cpuUsage > 90) {
            alertService.sendHighCPUAlert(cpuUsage);
        }
        
        if (memoryUsage > 90) {
            alertService.sendHighMemoryAlert(memoryUsage);
        }
    }
}
```

### 2. 数据库性能调优

```sql
-- 自动性能分析视图
CREATE VIEW pg_stat_statements_info AS
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    stddev_time,
    rows,
    shared_blks_hit,
    shared_blks_read,
    local_blks_hit,
    local_blks_read
FROM pg_stat_statements 
ORDER BY total_time DESC;

-- 索引使用情况分析
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes 
WHERE idx_scan < 100
ORDER BY idx_scan ASC;

-- 数据库连接池监控
SELECT 
    state,
    count(*) as connection_count,
    max(now() - state_change) as max_idle_time
FROM pg_stat_activity 
WHERE datname = 'device_management'
GROUP BY state;
```

## 总结

本高性能数据处理和存储方案提供了：

1. **流处理优化**: Flink集群配置优化、批量处理、内存管理
2. **消息队列优化**: Kafka集群配置、生产者和消费者优化
3. **存储优化**: InfluxDB集群、分区表、查询优化
4. **缓存架构**: 多级缓存、缓存一致性、性能监控
5. **数据压缩归档**: 压缩策略、数据生命周期管理
6. **性能监控**: 完整的监控体系和性能调优

该方案能够支撑3000+设备的高频数据处理需求，确保系统在大量数据压力下仍能保持高性能和高可用性。